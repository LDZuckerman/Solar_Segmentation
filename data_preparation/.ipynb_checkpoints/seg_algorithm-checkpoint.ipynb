{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to explore algorithmic data segmentations \n",
    "* For use with supervised models or in evaluation of unsupervised models\n",
    "* Segmentations computed using \"personal\" segmentation algorithm contributed to SunPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segment DKIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Segment DKIST VBI_2022_05 series [Oct 28, 2023]\n",
    "'''\n",
    "res = 0.016\n",
    "pad = 80 # 80 for Oct 28, need more padding than for others (bigger boarders)\n",
    "footprint = 200 #30\n",
    "files = [filename for filename in os.listdir(dir) if filename.startswith('VBI')]\n",
    "for file in files:\n",
    "    print(f'Input file {str(file)}')\n",
    "    savepath = f'{dir}SEGv2_{file}'\n",
    "    if os.path.exists(savepath):\n",
    "        print(f'\\t{savepath} Segmented data already exists')\n",
    "    else: \n",
    "        data = fits.open(dir+file)[0].data \n",
    "        header = fits.open(dir+file)[0].header\n",
    "        seg_data = funclib.segment_array_v2(data, resolution=res, mark_dim_centers=True, bp_max_size=0.18, footprint=footprint, pad=pad) \n",
    "        seg_hdu = fits.PrimaryHDU(seg_data)\n",
    "        raw_hdu = fits.ImageHDU(data)\n",
    "        hdu = fits.HDUList([seg_hdu, raw_hdu])\n",
    "        print(f'\\tWriting segmented data to '+str(savepath))\n",
    "        hdu.writeto(savepath, overwrite=True)\n",
    "print(f'Done all {len(files)} files'); a=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Check full segmented Oct 28 images\n",
    " - One bad one... idk what to do with that. Should I throw it out now? Maybe but im not going to.\n",
    "'''\n",
    "files = [file for file in os.listdir(dir) if file.startswith('SEG')]\n",
    "n = int((np.floor(np.sqrt(len(files)/4))))\n",
    "idx = 0\n",
    "fig, axs = plt.subplots(n, n, figsize=(80,80))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if idx < n**2:\n",
    "            axs[i,j].imshow(fits.open(f'{dir}{files[idx]}')[0].data)\n",
    "            axs[i,j].set_title(files[idx])\n",
    "            idx += 1\n",
    "        axs[i,j].xaxis.set_tick_params(labelbottom=False); axs[i,j].yaxis.set_tick_params(labelleft=False); axs[i,j].set_xticks([]); axs[i,j].set_yticks([])\n",
    "plt.savefig('DISKT_series_Oct28_segs_a'); print('Saved fig')\n",
    "fig, axs = plt.subplots(n, n, figsize=(20,20))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if idx < 2*n**2:\n",
    "            axs[i,j].imshow(fits.open(f'{dir}{files[idx]}')[0].data)\n",
    "            axs[i,j].set_title(files[idx])\n",
    "            idx += 1\n",
    "        axs[i,j].xaxis.set_tick_params(labelbottom=False); axs[i,j].yaxis.set_tick_params(labelleft=False); axs[i,j].set_xticks([]); axs[i,j].set_yticks([])\n",
    "plt.savefig('DISKT_series_Oct28_segs_b'); print('Saved fig')\n",
    "fig, axs = plt.subplots(n, n, figsize=(20,20))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if idx < 3*n**2:\n",
    "            axs[i,j].imshow(fits.open(f'{dir}{files[idx]}')[0].data)\n",
    "            axs[i,j].set_title(files[idx])\n",
    "            idx += 1\n",
    "        axs[i,j].xaxis.set_tick_params(labelbottom=False); axs[i,j].yaxis.set_tick_params(labelleft=False); axs[i,j].set_xticks([]); axs[i,j].set_yticks([])\n",
    "plt.savefig('DISKT_series_Oct28_segs_c'); print('Saved fig')\n",
    "fig, axs = plt.subplots(n, n, figsize=(20,20))\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if idx < 4*n**2:\n",
    "            axs[i,j].imshow(fits.open(f'{dir}{files[idx]}')[0].data)\n",
    "            axs[i,j].set_title(files[idx])\n",
    "            idx += 1\n",
    "        axs[i,j].xaxis.set_tick_params(labelbottom=False); axs[i,j].yaxis.set_tick_params(labelleft=False); axs[i,j].set_xticks([]); axs[i,j].set_yticks([])\n",
    "plt.savefig('DISKT_series_Oct28_segs_d'); print('Saved fig')\n",
    "bad = ['37_46_360']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are adjustments needed to segment real (non FL) DKIST?\n",
    "NOTE (7/14): is this how I ended up making segv2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Segment DKIST 2022_06_03 mosaic [Jun 16, 2023]\n",
    "    Ignore blurry ones which definitely wont be good. \n",
    "    For spiky ones, segment on corner region removed, then add padding of zero to keep size the same\n",
    "'''\n",
    "\n",
    "dir = '../Data/All_DKIST/'\n",
    "skip = ['VBI_59_14_4096']\n",
    "spike = ['VBI_31_21_4096', 'VBI_33_13_4096']\n",
    "files = [filename for filename in os.listdir(dir) if filename.startswith('VBI') and filename.endswith('_4096')] \n",
    "for file in files:\n",
    "    print(f'Input file {str(file)}')\n",
    "    savepath = f'{dir}SEG_{file}'\n",
    "    if os.path.exists(savepath):\n",
    "        print(f'\\t{savepath} Segmented data already exists')\n",
    "    else:\n",
    "        if any(tag in file for tag in skip): \n",
    "            print(f'\\tSkipping {tag} (gets stuck on this file)') # WHY??\n",
    "            continue \n",
    "        data = fits.open(dir+file)[1].data # for VBI files, data in HDU 1, for HM VBI files its in HDU 0\n",
    "        header = fits.open(dir+file)[1].header\n",
    "        if any(tag in file for tag in spike):\n",
    "            cutdata = data[0:data.shape[1]-300, 0:data.shape[1]-300] \n",
    "            seg_datacut = funclib.segment_array(cutdata, resolution=header['cdelt1'], mark_dim_centers=True)\n",
    "            seg_data = np.zeros_like(data) * np.NaN\n",
    "            seg_data[0:4096-300, 0:4096-300] = seg_datacut\n",
    "        else:\n",
    "            seg_data = funclib.segment_array(data, resolution=header['cdelt1'], mark_dim_centers=True) #resolution=0.016)\n",
    "        seg_hdu = fits.PrimaryHDU(seg_data)\n",
    "        raw_hdu = fits.ImageHDU(data)\n",
    "        hdu = fits.HDUList([seg_hdu, raw_hdu])\n",
    "        print(f'\\tWriting segmented data to '+str(savepath))\n",
    "        hdu.writeto(savepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Examine Jun16 segmentations\n",
    "    OOOY these are crappy.\n",
    "    Most of them do have BP just very very very few (see fits.open('../Data/All_DKIST/SEG_VBI_04_05_4096')[0].data[0:1000, 0:1000]).\n",
    "    Also too much IG.\n",
    "'''\n",
    "dir = '../Data/All_DKIST/'\n",
    "jun16tags = ['17_20', '17_23', '24_08', '24_23', '24_26', '25_39', '28_27', '31_21', '36_25', '04_05', '04_08', '04_11', '04_14', '04_17', '04_20', '04_23', '04_26', '04_29', '15_12', '15_15', '23_31', '23_34', '30_14', '31_27', '31_33', '32_52', '33_13', '37_15', '42_22', '42_31', '42_34', '46_32', '56_11', '56_20', '56_23', '59_14']\n",
    "files = [filename for filename in os.listdir(dir) if filename.startswith('SEG_VBI') and filename.endswith('_4096') and any(tag in filename for tag in jun16tags)] \n",
    "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8), (ax9, ax10), (ax11, ax12), (ax13, ax14), (ax15, ax16), (ax17, ax18), (ax19, ax20), (ax21, ax22), (ax23, ax24), (ax25, ax26), (ax27, ax28), (ax29, ax30), (ax31, ax32), (ax33, ax34), (ax35, ax36)) =  plt.subplots(18, 2, figsize=(25, 200)); axs = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12, ax13, ax14, ax15, ax16, ax17, ax18, ax19, ax20, ax21, ax22, ax23, ax24, ax25, ax26, ax27, ax28, ax29, ax30, ax31, ax32, ax33, ax34, ax35, ax36]\n",
    "for i in range(0, len(files)):\n",
    "    segdata = fits.open(dir+files[i])[0].data\n",
    "    axs[i].set_title(files[i])\n",
    "    #im = axs[i].imshow(segdata, origin='lower')\n",
    "    justbp = np.zeros_like(segdata)*np.NaN\n",
    "    justbp[segdata == 1.5] = 1\n",
    "    im = axs[i].imshow(justbp, origin='lower')\n",
    "    plt.colorbar(im, ax=axs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Perhaps I could try adjusting thresholds? Or actually maybe HM would help.\n",
    "    No.. that gets rid of the too much IG, but makes too much GR\n",
    "'''\n",
    "\n",
    "data = fits.open('../Data/All_DKIST/VBI_04_05_4096')[1].data\n",
    "header = fits.open('../Data/All_DKIST/VBI_04_05_4096')[1].header\n",
    "HMdata = funclib.match_to_firstlight(data)\n",
    "hdu = fits.PrimaryHDU(HMdata, header=header)\n",
    "hdu.writeto('../Data/All_DKIST/HM_VBI_04_05_4096', overwrite=True)\n",
    "segHMdata = funclib.segment_array(HMdata, resolution=header['cdelt1'], mark_dim_centers=True), #resolution=0.016)\n",
    "seg_hdu = fits.PrimaryHDU(segHMdata)\n",
    "raw_hdu = fits.ImageHDU(data)\n",
    "hdu = fits.HDUList([seg_hdu, raw_hdu])\n",
    "hdu.writeto('../Data/All_DKIST/SEG_HM_VBI_04_05_4096', overwrite=True)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
    "data = fits.open('../Data/All_DKIST/VBI_04_05_4096')[1].data\n",
    "im1 = ax1.imshow(data, origin='lower')\n",
    "ax1.set_title('Image')\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "segdata = fits.open('../Data/All_DKIST/SEG_VBI_04_05_4096')[0].data\n",
    "im2 = ax2.imshow(np.squeeze(segdata), origin='lower')\n",
    "ax2.set_title('Seg without HM')\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "segHMdata = fits.open('../Data/All_DKIST/SEG_HM_VBI_04_05_4096')[0].data\n",
    "im3 = ax3.imshow(np.squeeze(segHMdata), origin='lower')\n",
    "ax3.set_title('Seg with HM')\n",
    "plt.colorbar(im3, ax=ax3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Lets try to adjust bp threshold? original is np.nanmean(data) + 0.5 * np.nanstd(data)\n",
    "    BPL1: fac_brightness_limit = np.nanmean(data) + 0.25 * np.nanstd(data) --> very little change \n",
    "    BPL2: no fac_brightness_limit --> still very little change\n",
    "    BPSL1: fac_pix_limit = 500 (for all VBI files, cdelt1 is 0.01099 so pix limit defualts to 181.8) --> again negligable change\n",
    "    BPSL2: no pix size limit (fac_pix_limit = 100000000) --> yep, good. Marks lot of gr as fac as expected\n",
    "    BPSL3: fac_pix_limit = 1000 --> much more fac! But how many do I want??\n",
    "'''\n",
    "\n",
    "data = fits.open('../Data/All_DKIST/VBI_04_05_4096')[1].data\n",
    "header = fits.open('../Data/All_DKIST/VBI_04_05_4096')[1].header\n",
    "segBPSL3data = funclib.segment_array(data, resolution=header['cdelt1'], mark_dim_centers=True, fac_pix_limit = 1000) #resolution=0.016)\n",
    "seg_hdu = fits.PrimaryHDU(segBPSL3data)\n",
    "raw_hdu = fits.ImageHDU(data)\n",
    "hdu = fits.HDUList([seg_hdu, raw_hdu])\n",
    "hdu.writeto('../Data/All_DKIST/SEGBPSL3_VBI_04_05_4096', overwrite=True)\n",
    "\n",
    "HMdata = fits.open('../Data/All_DKIST/HM_VBI_04_05_4096')[0].data\n",
    "segBPSL3HMdata = funclib.segment_array(HMdata, resolution=header['cdelt1'], mark_dim_centers=True, fac_pix_limit = 1000) #resolution=0.016)\n",
    "seg_hdu = fits.PrimaryHDU(segBPSL3HMdata)\n",
    "raw_hdu = fits.ImageHDU(data)\n",
    "hdu = fits.HDUList([seg_hdu, raw_hdu])\n",
    "hdu.writeto('../Data/All_DKIST/SEGBPSL3_HM_VBI_04_05_4096', overwrite=True)\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8) = plt.subplots(8, 1, figsize=(5, 40))\n",
    "data = fits.open('../Data/All_DKIST/VBI_04_05_4096')[1].data\n",
    "im1 = ax1.imshow(data, origin='lower')\n",
    "ax1.set_title('Image')\n",
    "plt.colorbar(im1, ax=ax1)\n",
    "segdata = fits.open('../Data/All_DKIST/SEG_VBI_04_05_4096')[0].data\n",
    "im2 = ax2.imshow(np.squeeze(segdata), origin='lower')\n",
    "ax2.set_title('Seg without HM')\n",
    "plt.colorbar(im2, ax=ax2)\n",
    "segBPL2data = fits.open('../Data/All_DKIST/SEGBPL2_VBI_04_05_4096')[0].data\n",
    "im3 = ax3.imshow(np.squeeze(segBPL2data), origin='lower')\n",
    "ax3.set_title('Seg without HM, no brightness threshold')\n",
    "plt.colorbar(im3, ax=ax3)\n",
    "segBPSL3data = fits.open('../Data/All_DKIST/SEGBPSL3_VBI_04_05_4096')[0].data\n",
    "im4 = ax4.imshow(np.squeeze(segBPSL3data), origin='lower')\n",
    "ax4.set_title('Seg without HM, pix limit 1000')\n",
    "plt.colorbar(im4, ax=ax4)\n",
    "\n",
    "HMdata = fits.open('../Data/All_DKIST/HM_VBI_04_05_4096')[0].data\n",
    "im5 = ax5.imshow(np.squeeze(HMdata), origin='lower')\n",
    "ax5.set_title('HM Image')\n",
    "plt.colorbar(im5, ax=ax5)\n",
    "segHMdata = fits.open('../Data/All_DKIST/SEG_HM_VBI_04_05_4096')[0].data\n",
    "im6 = ax6.imshow(np.squeeze(segHMdata), origin='lower')\n",
    "ax6.set_title('Seg with HM')\n",
    "plt.colorbar(im6, ax=ax6)\n",
    "segBPL2HMdata = fits.open('../Data/All_DKIST/SEGBPL2_HM_VBI_04_05_4096')[0].data\n",
    "im7 = ax7.imshow(np.squeeze(segBPL2HMdata), origin='lower')\n",
    "ax7.set_title('Seg with HM, no brightness limit')\n",
    "plt.colorbar(im7, ax=ax7)\n",
    "segBPSL3HMdata = fits.open('../Data/All_DKIST/SEGBPSL3_HM_VBI_04_05_4096')[0].data\n",
    "im8 = ax8.imshow(np.squeeze(segBPSL3HMdata), origin='lower')\n",
    "ax8.set_title('Seg with HM, pix limit 100')\n",
    "plt.colorbar(im8, ax=ax8)\n",
    "\n",
    "'''\n",
    "Ok, this shows a few things.\n",
    "Main issue is all non-firstlight images have both varying res and more importantly varying overall brightness\n",
    "Unfortunately, histogram matching doesnt really sovle the varying brightness; its still there\n",
    "Obvioulsy my seg algo just doenst work with varying brightness, since it applies a uniform initial threhsold\n",
    "Thus, it will allways ether overclassify IG in dim regions, or underclassify IG in bright regions, depending on pixel dist\n",
    "I realy dont know how I would make there be a spatially-varying threshold\n",
    "Another issue is that regions with lots of bp which I want) don't get segmented into granules with bp on top, but instead just weird, erratic granules\n",
    "This means that it is going to be really really hard to get good segmentations that contain lots of bp\n",
    "But maybe there will still be pieces I can pick out that do have \"good\" results.\n",
    "Need to figure out how to get, if not actually good segmentations, segmentations that result in many good pieces\n",
    "Ok, so using higher pix limit (allowing bigger things to be bp works).. but why???\n",
    "Should change the fac_pix_limit = fac_size_limit / resolution, with fac_size_limit = 2\"/pix??\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MURaM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Perform segmentations\n",
    "'''\n",
    "\n",
    "dir = '../Data/MURaM/'\n",
    "res = 0.0211\n",
    "imgfiles = [filename for filename in os.listdir(dir) if filename.startswith('I_out')]\n",
    "print(f\"Currently have segmented {len([filename for filename in os.listdir(dir) if filename.startswith('SEGv2')])} out of {len(imgfiles)} MURaM files\")\n",
    "files = np.random.choice(imgfiles, size = 1801) # Do all of them! ['I_out.010890.fits.gz']\n",
    "n_added = 0\n",
    "for file in files:\n",
    "    print(f'Input file {str(file)}')\n",
    "    savepath = f'{dir}SEGv2_{file}'\n",
    "    if os.path.exists(savepath):\n",
    "        print(f'\\t{savepath} Segmented data already exists')\n",
    "    else: \n",
    "        data = fits.open(dir+file)[0].data \n",
    "        header = fits.open(dir+file)[0].header\n",
    "        seg_data = funclib.segment_array_v2(data, resolution=res, mark_dim_centers=True, bp_max_size=0.18, footprint=30) #resolution=0.016)\n",
    "        seg_hdu = fits.PrimaryHDU(seg_data)\n",
    "        raw_hdu = fits.ImageHDU(data)\n",
    "        hdu = fits.HDUList([seg_hdu, raw_hdu])\n",
    "        print(f'\\tWriting segmented data to '+str(savepath))\n",
    "        hdu.writeto(savepath, overwrite=True)\n",
    "        n_added += 1\n",
    "print(f'Done all {len(files)} files. Added {n_added} segs.')\n",
    "print(f\"Currently have segmented {len([filename for filename in os.listdir(dir) if filename.startswith('SEGv2')])} out of {len(imgfiles)} MURaM files\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert back from 4-class to 3 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create UNetData_v2_subset/seg_images_binary anologous to UNetData_v2_subset/seg_images\n",
    "'''\n",
    "\n",
    "# dir = \"../Data/UNetData_v2_subset/\"\n",
    "# for file in os.listdir(f'{dir}seg_images/train/'):\n",
    "#     if os.path.exists(f'{dir}seg_images_binary/train/{file}') == False:\n",
    "#         seg = np.load(f'{dir}seg_images/train/{file}')\n",
    "#         binseg = funclib.convert_back(seg, to='binary')\n",
    "#         np.save(f'{dir}seg_images_binary/train/{file}', binseg)\n",
    "# for file in os.listdir(f'{dir}seg_images/val/'):\n",
    "#     if os.path.exists(f'{dir}seg_images_binary/val/{file}') == False:\n",
    "#         seg = np.load(f'{dir}seg_images/val/{file}')\n",
    "#         binseg = funclib.convert_back(seg, to='binary')\n",
    "#         np.save(f'{dir}seg_images_binary/val/{file}', binseg)\n",
    "\n",
    "'''\n",
    "Going back to using just first light, but lets also do it on only 3 classes. \n",
    "Create UNetData_v2_subset/seg_images_ternary anologous to UNetData_v2_subset/seg_images\n",
    "'''\n",
    "\n",
    "# dir = \"../Data/UNetData/\"\n",
    "# for file in os.listdir(f'{dir}seg_images/train/'):\n",
    "#     if os.path.exists(f'{dir}seg_images_ternary/train/{file}') == False:\n",
    "#         seg = np.load(f'{dir}seg_images/train/{file}')\n",
    "#         triseg = funclib.convert_back(seg, to='ternary')\n",
    "#         np.save(f'{dir}seg_images_ternary/train/{file}', triseg)\n",
    "# for file in os.listdir(f'{dir}seg_images/val/'):\n",
    "#     if os.path.exists(f'{dir}seg_images_ternary/val/{file}') == False:\n",
    "#         seg = np.load(f'{dir}seg_images/val/{file}')\n",
    "#         triseg = funclib.convert_back(seg, to='ternary')\n",
    "#         np.save(f'{dir}seg_images_ternary/val/{file}', triseg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchkernel",
   "language": "python",
   "name": "torchkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
