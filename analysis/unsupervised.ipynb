{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import astropy.io.fits as fits\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import importlib\n",
    "sys.path.insert(0, '../utils')\n",
    "import data_utils, run_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WNet_name</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>channels</th>\n",
       "      <th>weights</th>\n",
       "      <th>randomSharp</th>\n",
       "      <th>smooth_loss</th>\n",
       "      <th>blob_loss</th>\n",
       "      <th>padding_mode</th>\n",
       "      <th>load_model</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WNet29nm</td>\n",
       "      <td>3</td>\n",
       "      <td>[X]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>zeroes</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WNet31nm</td>\n",
       "      <td>3</td>\n",
       "      <td>[X]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>reflect</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WNet34nm</td>\n",
       "      <td>3</td>\n",
       "      <td>[X, median_residual]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>reflect</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WNet35nm</td>\n",
       "      <td>3</td>\n",
       "      <td>[X, median_residual]</td>\n",
       "      <td>[1, 4]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>reflect</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WNet36nm</td>\n",
       "      <td>3</td>\n",
       "      <td>[X]</td>\n",
       "      <td>[1]</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>replicate</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  WNet_name  n_classes              channels weights  randomSharp  \\\n",
       "0  WNet29nm          3                   [X]  [1, 4]        False   \n",
       "1  WNet31nm          3                   [X]  [1, 4]        False   \n",
       "2  WNet34nm          3  [X, median_residual]     [1]        False   \n",
       "3  WNet35nm          3  [X, median_residual]  [1, 4]        False   \n",
       "4  WNet36nm          3                   [X]     [1]        False   \n",
       "\n",
       "   smooth_loss  blob_loss padding_mode  load_model  num_epochs  learning_rate  \n",
       "0         True      False       zeroes       False           3         0.0003  \n",
       "1         True      False      reflect       False           3         0.0003  \n",
       "2         True      False      reflect       False           3         0.0003  \n",
       "3         True      False      reflect       False           3         0.0003  \n",
       "4         True      False    replicate       False           3         0.0003  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Quickly summarize trained models\n",
    "'''\n",
    "\n",
    "models = json.load(open('../../WNet_runs/exp_dicts.json'))\n",
    "mods = pd.DataFrame(models).drop(columns=['img_dir', 'seg_dir', 'img_size', 'num_sup', 'freeze_dec', 'batch_size'])\n",
    "mods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Display a random sample of images for one model\n",
    "'''\n",
    "\n",
    "WNet_num = '35nm'\n",
    "output_dir = f'../../UNet_runs/exp{WNet_num}/WNet{WNet_num}_outputs'\n",
    "fig, axs = plt.subplots(5, 3, figsize=(8, 13))\n",
    "axs[0,0].set_title('Image')\n",
    "axs[0,1].set_title('Algorithmic Labels')\n",
    "axs[0,2].set_title('WNet Labels')\n",
    "target_pos = 2 if 'timeseries' in mods[mods['WNet_name']==f\"WNet{WNet_num}\"] else 0\n",
    "for i in range(0, 14, 3):\n",
    "    idx = np.random.randint(0, len([file for file in os.listdir(output_dir) if file.startswith('x')]))\n",
    "    im = np.load(f'{output_dir}/x_{idx}.npy')[target_pos]\n",
    "    true = np.load(f'{output_dir}/true_{idx}.npy')\n",
    "    preds = np.squeeze(np.load(f'{output_dir}/pred_{idx}.npy'))\n",
    "    axs[i,0].imshow(im, cmap='gist_gray'); axs[i].set_ylabel(idx)\n",
    "    axs[i,1].imshow(true, vmin=0, vmax=1.5, cmap='gist_gray')\n",
    "    axs[i,2].imshow(preds, vmin=0, vmax=1.5, cmap='gist_gray')\n",
    "    axs[i,0].xaxis.set_tick_params(labelbottom=False); axs[i,0].yaxis.set_tick_params(labelleft=False); axs[i,0].set_xticks([]); axs[i,0].set_yticks([])\n",
    "    axs[i,1].xaxis.set_tick_params(labelbottom=False); axs[i,1].yaxis.set_tick_params(labelleft=False); axs[i,1].set_xticks([]); axs[i,1].set_yticks([])\n",
    "    axs[i,2].xaxis.set_tick_params(labelbottom=False); axs[i,2].yaxis.set_tick_params(labelleft=False); axs[i,2].set_xticks([]); axs[i,2].set_yticks([])\n",
    "plt.savefig(f'{output_dir}/WNet{WNet_num}_val_examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compare models\n",
    "'''\n",
    "\n",
    "idx = 131 # 161 # np.random.randint(0, 108)  # 131 # 131 is good image for full DKIST seg v1  (\"true\" seg here is still version; does not matter for training unsup, but perhaps for comparing validations)\n",
    "models = list(mods['WNet_name']) # models on properly normalized data!\n",
    "fig, axs = plt.subplots(len(models), 3, figsize=(9, 3*len(models)))\n",
    "for i in range(len(models)):\n",
    "    output_dir = f'../NN_outputs/{models[i]}_outputs'\n",
    "    target_pos = 2 if models[i]=='WNet15m' else 0\n",
    "    im = np.load(f'{output_dir}/x_{idx}.npy')[target_pos] # index to get image\n",
    "    true = np.load(f'{output_dir}/true_{idx}.npy')\n",
    "    preds = np.squeeze(np.load(f'{output_dir}/pred_{idx}.npy'))\n",
    "    if int(preds[40, 60]) == 0: # try to mostly have black be zero\n",
    "        preds_copy = np.copy(preds)\n",
    "        preds[preds_copy == 0.0] = 1\n",
    "        preds[preds_copy == 1.0] = 0 \n",
    "    axs[i,1].set_title(f'{models[i]}')\n",
    "    axs[i,0].imshow(im, cmap='gist_gray')\n",
    "    axs[i,1].imshow(true, vmin=0, vmax=1.5, cmap='gist_gray')\n",
    "    axs[i,2].imshow(preds, vmin=0, vmax=1.5, interpolation='none', cmap='tab10') #cmap='gist_gray')#cmap='tab10')\n",
    "    axs[i,0].xaxis.set_tick_params(labelbottom=False); axs[i,0].yaxis.set_tick_params(labelleft=False); axs[i,0].set_xticks([]); axs[i,0].set_yticks([])\n",
    "    axs[i,1].xaxis.set_tick_params(labelbottom=False); axs[i,1].yaxis.set_tick_params(labelleft=False); axs[i,1].set_xticks([]); axs[i,1].set_yticks([])\n",
    "    axs[i,2].xaxis.set_tick_params(labelbottom=False); axs[i,2].yaxis.set_tick_params(labelleft=False); axs[i,2].set_xticks([]); axs[i,2].set_yticks([])\n",
    "plt.savefig('ExamplePredictions_OneImage.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Traditional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "path = \"../Data/All_DKIST/FirstLight.fits\"\n",
    "data = fits.open(path)[0].data\n",
    "labels = np.squeeze(fits.open(\"../Data/All_DKIST/SEGv2_FirstLight\")[0].data) # just to check against\n",
    "\n",
    "# Cut and flatten\n",
    "data = data[100:300, 100:300]\n",
    "labels = labels[100:300, 100:300]\n",
    "dataflat = data.reshape(-1)\n",
    "\n",
    "# Plot for comparison\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(data, cmap='gray', origin='lower')\n",
    "plt.title('Initial data (HE)')\n",
    "plt.figure()\n",
    "\n",
    "# Create features and put into df (skip kernel feature for now - contain inf and probably not super useful anyway)\n",
    "df = pd.DataFrame()\n",
    "df['OG_value'] = dataflat\n",
    "df = data_utils.add_gradient_feats(df, data) # Add value of (non-HE) gradient as feature\n",
    "df = data_utils.add_sharpening_feats(df, dataflat) # Add value of sharpening filters as features RIGHT NOW JUST SQUARED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "KMeans (best)\n",
    "    Clusters by separating into n groups of equal variance, minimizing within-cluster sum-of-squares\n",
    "    Overall, this seems to overestimate IGM\n",
    "    Could try using large n_clusters, then combineing.\n",
    "'''\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Explore hyperparameters\n",
    "n_clusterss = [2, 3, 5, 7]\n",
    "inits = ['k-means++', 'random'] # can also try passing locs of centers if use another alg to determine\n",
    "\n",
    "dict = {}\n",
    "i = 0\n",
    "for n_clusters in n_clusterss:\n",
    "    for init in inits:\n",
    "        preds_flat = KMeans(n_clusters=n_clusters, init=init, n_init=10).fit(df.values).labels_\n",
    "        preds = np.reshape(preds_flat, (np.shape(data)[0], np.shape(data)[1]))\n",
    "        preds = data_utils.post_process(preds) # make sure IG is assigned to 0, G to 1\n",
    "        dict[str(i)] = [n_clusters, init, preds]\n",
    "        i += 1\n",
    "        pct_correct = len(np.where(preds.reshape(-1)==labels.reshape(-1))[0])/len(preds.reshape(-1))\n",
    "        print('    n_clusters='+str(n_clusters)+', init='+str(init)+ ', \"accuracy\":', pct_correct)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "fig.suptitle('KMeans')\n",
    "axs = [ax1, ax2]\n",
    "for i in range(len(axs)):\n",
    "    n_clusters =  dict[str(i)][0]\n",
    "    init = dict[str(i)][1]\n",
    "    preds = dict[str(i)][2]\n",
    "    axs[i].imshow(preds, origin='lower')\n",
    "    axs[i].set_title('n_clusters='+str(n_clusters)+', init='+str(init))\n",
    "\n",
    "\n",
    "# With \"best\" hyperparameters\n",
    "n_clusters = 7\n",
    "preds_flat = KMeans(n_clusters=n_clusters, init='random', n_init=10).fit(df.values).labels_\n",
    "preds = np.reshape(preds_flat, (np.shape(data)[0], np.shape(data)[1]))\n",
    "\n",
    "def kmeans_to_seg(preds, data, resolution=0.016, bp_max_size=0.15):\n",
    "    seg = np.zeros_like(data)*np.NaN\n",
    "    # HE\n",
    "    data_norm = ((data - np.nanmin(data))/(np.nanmax(data) - np.nanmin(data))) * 225 # min-max normalization to [0, 225] \n",
    "    data_HE = sk.filters.rank.equalize(data_norm.astype(int), footprint=sk.morphology.disk(250))\n",
    "    data_HE = data_HE[100:300, 100:300]\n",
    "    bp_min_pix = (bp_max_size / resolution)**2 # 87\n",
    "    bp_min_flux = np.nanmean(data) + 0.25 * np.nanstd(data) \n",
    "    ig_max_flux = np.nanmean(data) - 0.25 * np.nanstd(data)\n",
    "    labeled_preds = skimage.measure.label(preds + 1, connectivity=2)\n",
    "    values = np.unique(labeled_preds) \n",
    "    for value in values:\n",
    "        datavals = data[labeled_preds == value].flatten()\n",
    "        if (np.nanmean(datavals) <= ig_max_flux):\n",
    "            seg[labeled_preds == value] = 0\n",
    "        if (np.nanmean(datavals) > ig_max_flux): #and (len(datavals) > bp_min_pix): #(np.nanmean(datavals) < bp_min_flux):\n",
    "            seg[labeled_preds == value] = 1\n",
    "            if (len(datavals) < bp_min_pix) and np.max(datavals) > bp_min_flux:\n",
    "                seg[labeled_preds == value] = 1.5\n",
    "    return seg\n",
    "\n",
    "seg = kmeans_to_seg(preds, data)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 3.5))\n",
    "fig.suptitle('KMeans (n_clusters=7, init=\"random\")')\n",
    "ax1.imshow(data, cmap='gray', origin='lower'); ax1.set_title('data')\n",
    "ax2.imshow(preds, origin='lower'); ax2.set_title('kmeans preds')\n",
    "ax3.imshow(seg, origin='lower'); ax3.set_title('kmeans pred -> seg')\n",
    "fig, axs = plt.subplots(n_clusters, 1, figsize=(7, 2*n_clusters))\n",
    "i = 0\n",
    "axs[-1].set_ylabel('Flux')\n",
    "for group in np.unique(preds):\n",
    "    axs[i].hist(data[preds == group], bins=20); axs[i].set_ylabel(f'Group {i}')\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Agglomorative Clustering\n",
    "    Build clusters by finding closest pairs, merging iteratively \n",
    "    Does best with 3 clusters, 'complete' linkage, 'euclidean' metric:\n",
    "    Without gradient feature, 3rd cluster becomes rings around granules, not brightpoints\n",
    "    With gradient feature, maybe finds dim middles?\n",
    "'''\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Explore hyperparameters\n",
    "n_clusterss = [2, 3] \n",
    "metrics = ['euclidean'] #  'l1', 'manhattan' seem to do similarly (at least with n_clusters=2) \n",
    "linkages = ['complete', 'ward'] # 'average' and 'single' do terrible\n",
    "\n",
    "dict = {}\n",
    "i = 0\n",
    "for n_clusters in n_clusterss:\n",
    "    for metric in metrics:\n",
    "        for linkage in linkages:\n",
    "            preds_flat = AgglomerativeClustering(n_clusters=n_clusters, metric=metric, linkage=linkage).fit(df.values).labels_\n",
    "            preds = np.reshape(preds_flat, (np.shape(data)[0], np.shape(data)[1]))\n",
    "            preds = data_utils.post_process(preds) # make sure IG is addigned to 0, G to 1\n",
    "            dict[str(i)] = [n_clusters, metric, linkage, preds]\n",
    "            i += 1\n",
    "            pct_correct = len(np.where(preds.reshape(-1)==labels.reshape(-1))[0])/len(preds.reshape(-1))\n",
    "            print('    n_clusters='+str(n_clusters)+', linkage='+str(linkage)+ ', \"accuracy\":', pct_correct)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))\n",
    "fig.suptitle('AgglomorativeClustering')\n",
    "axs = [ax1, ax2]\n",
    "for i in range(len(axs)):\n",
    "    n_clusters =  dict[str(i)][0]\n",
    "    metric = dict[str(i)][1]\n",
    "    linkage = dict[str(i)][2]\n",
    "    preds = dict[str(i)][3]\n",
    "    axs[i].imshow(preds, origin='lower')\n",
    "    axs[i].set_title('n_clusters='+str(n_clusters)+', linkage='+str(linkage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DBSCAN \n",
    "    Clusters by identifying areas of high density separated by areas of low density \n",
    "    MUCH faster than OPTICS, but same very \"poor\" results\n",
    "'''\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Explore hyperparameters\n",
    "epss = [10, 30] # must be larger for more features (0.5 works fine for 1 feature)\n",
    "min_sampless = [50, 100, 200]\n",
    "metric = 'euclidean'\n",
    "algorithm = 'auto'\n",
    "\n",
    "dict = {}\n",
    "i = 0\n",
    "for eps in epss:\n",
    "    for min_samples in min_sampless:\n",
    "        preds_flat = DBSCAN(eps=eps, min_samples=min_samples, metric=metric, algorithm=algorithm, n_jobs=3).fit(df.values).labels_\n",
    "        preds = np.reshape(preds_flat, (np.shape(data)[0], np.shape(data)[1]))\n",
    "        dict[str(i)] = [eps, min_samples, preds]\n",
    "        i += 1\n",
    "\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('DBSCAN', color='white')\n",
    "axs = [ax1, ax2, ax3, ax4, ax5, ax6]\n",
    "for i in range(len(axs)):\n",
    "    eps =  dict[str(i)][0]\n",
    "    min_samples = dict[str(i)][1]\n",
    "    preds = dict[str(i)][2]\n",
    "    axs[i].imshow(preds, origin='lower')\n",
    "    axs[i].set_title('eps='+str(eps)+', min_samps='+str(min_samples), color=tc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
